package com.farhannz.kaitou.helpers

import com.farhannz.kaitou.data.models.TokenInfo
import org.apache.lucene.analysis.ja.Token

class TokenManager {

    fun mergeWithDictionary(tokens: List<TokenInfo>, dict: Set<String>?, maxGram: Int = 6): List<TokenInfo> {
        // Add before merging
        val filteredTokens = tokens.map {
            if (it.surface in setOf("!", "?", "ï¼", "ï¼Ÿ", "ã€‚", "ã€")) {
                it.copy(partOfSpeech = "è¨˜å·") // Mark as symbol
            } else it
        }
        val result = mutableListOf<TokenInfo>()
        var i = 0
        while (i < filteredTokens.size) {
            var merged: TokenInfo? = null
            outer@ for (n in maxGram downTo 2) {
                if (i + n > filteredTokens.size) continue
                val span = filteredTokens.subList(i, i + n)
                val text = span.joinToString("") { it.surface } // Always use surface form

// Special case: Allow particle + auxiliary verb merging
                val allowMerge = span.all { token ->
                    when {
                        token.partOfSpeech.startsWith("åŠ©è©") -> true // Allow particles
                        token.partOfSpeech.startsWith("åŠ©å‹•è©") -> true
                        token.partOfSpeech.startsWith("åè©") -> true
                        token.partOfSpeech.startsWith("å‹•è©") -> true
                        else -> false
                    }
                }

                if (allowMerge && dict?.contains(text) ?: false) {
                    // Preserve original surface but use first POS
                    merged = TokenInfo(text, text, span.first().partOfSpeech)
                    i += n
                    break@outer
                }
            }
            result.add(merged ?: filteredTokens[i])
            i += if (merged != null) 0 else 1
        }
        return result
    }

    fun correctAuxiliaryNegative(tokens: List<TokenInfo>): List<TokenInfo> {
        return tokens.mapIndexed { i, token ->
            when {
                // Rule 1: Correct ãªã„ after particles
                token.surface == "ãªã„" && i > 0 && tokens[i-1].surface == "ã¯" ->
                    token.copy(partOfSpeech = "åŠ©å‹•è©")

                // Rule 2: Correct ãªã„ after verbs
                token.surface == "ãªã„" && i > 0 && tokens[i-1].partOfSpeech.startsWith("å‹•è©") ->
                    token.copy(partOfSpeech = "åŠ©å‹•è©")

                // Rule 3: Handle common negative forms
                token.surface in setOf("ã‚“", "ãš") ->
                    token.copy(partOfSpeech = "åŠ©å‹•è©")

                else -> token
            }
        }
    }
    // Helper for composite POS
    private fun determineCompositePos(span: List<TokenInfo>): String {
        // Custom logic based on span tokens
        return if (span.any { it.partOfSpeech.startsWith("åŠ©è©") }) "compound"
        else span.last().partOfSpeech
    }

// Taken from https://is.muni.cz/th/opw9s/Thesis___Analyzer_of_Japanese_Texts_for_Language_Learning_Purposes.pdf
/*
    Algorithm 1 Concatenation of N-grams
    procedure concatenateNgrams(ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›ğ‘ )
        ğ‘– â† 0
        while ğ‘– < ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›ğ‘ .ğ‘™ğ‘’ğ‘›ğ‘”ğ‘¡â„ do
            ğ‘šğ‘’ğ‘Ÿğ‘”ğ‘’ğ‘‘ğ‘Šğ‘œğ‘Ÿğ‘‘ â† ğ‘šğ‘ğ‘¡ğ‘â„ğ‘Šğ‘œğ‘Ÿğ‘‘(ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›ğ‘ , ğ‘–)
            ğ‘– â† ğ‘– + ğ‘šğ‘’ğ‘Ÿğ‘”ğ‘’ğ‘‘ğ‘Šğ‘œğ‘Ÿğ‘‘.ğ‘›ğ‘”ğ‘Ÿğ‘ğ‘š.ğ‘™ğ‘’ğ‘›ğ‘”ğ‘¡â„
            end while
        end procedure

    function matchWord(ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›ğ‘ , ğ‘œğ‘“ ğ‘“ ğ‘ ğ‘’ğ‘¡)
        ğ‘›ğ‘”ğ‘Ÿğ‘ğ‘šğ‘†ğ‘–ğ‘§ğ‘’ â† 4
        while ğ‘›ğ‘”ğ‘Ÿğ‘ğ‘šğ‘†ğ‘–ğ‘§ğ‘’ > 0 do
            ğ‘›ğ‘”ğ‘Ÿğ‘ğ‘š â† ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›ğ‘ [ğ‘œğ‘“ ğ‘“ ğ‘ ğ‘’ğ‘¡ âˆ¶ ğ‘œğ‘“ ğ‘“ ğ‘ ğ‘’ğ‘¡ + ğ‘›ğ‘”ğ‘Ÿğ‘ğ‘šğ‘†ğ‘–ğ‘§ğ‘’]
            â–· Get the surface form from all the n-gram tokens but the last and the dictionary form from the last token:
            ğ‘ğ‘Ÿğ‘’ğ‘“ ğ‘–ğ‘¥ğ‘†ğ‘¢ğ‘Ÿğ‘“ ğ‘ğ‘ğ‘’ğ‘  â† ğ‘›ğ‘”ğ‘Ÿğ‘ğ‘š[0 âˆ¶ ğ‘›ğ‘”ğ‘Ÿğ‘ğ‘šğ‘†ğ‘–ğ‘§ğ‘’ âˆ’ 1].ğ‘šğ‘ğ‘(ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘› â†’ ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›.ğ‘ ğ‘¢ğ‘Ÿğ‘“ ğ‘ğ‘ğ‘’).ğ‘—ğ‘œğ‘–ğ‘›()
            ğ‘¤ğ‘œğ‘Ÿğ‘‘ â† ğ‘ğ‘Ÿğ‘’ğ‘“ ğ‘–ğ‘¥ğ‘†ğ‘¢ğ‘Ÿğ‘“ ğ‘ğ‘ğ‘’ğ‘  + ğ‘›ğ‘”ğ‘Ÿğ‘ğ‘š[ğ‘›ğ‘”ğ‘Ÿğ‘ğ‘šğ‘†ğ‘–ğ‘§ğ‘’ âˆ’ 1].ğ‘‘ğ‘–ğ‘ğ‘¡
            if ğ‘¤ğ‘œğ‘Ÿğ‘‘ in ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘ğ‘Ÿğ‘¦ then
                return {ğ‘›ğ‘”ğ‘Ÿğ‘ğ‘š âˆ¶ ğ‘›ğ‘”ğ‘Ÿğ‘ğ‘š, ğ‘’ğ‘›ğ‘¡ğ‘Ÿğ‘–ğ‘’ğ‘  âˆ¶ ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘ğ‘Ÿğ‘¦[ğ‘¤ğ‘œğ‘Ÿğ‘‘]}
            end if
            ğ‘›ğ‘”ğ‘Ÿğ‘ğ‘šğ‘†ğ‘–ğ‘§ğ‘’ â† ğ‘›ğ‘”ğ‘Ÿğ‘ğ‘šğ‘†ğ‘–ğ‘§ğ‘’ âˆ’ 1
        end while
        return {ğ‘›ğ‘”ğ‘Ÿğ‘ğ‘š âˆ¶ [ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›ğ‘ [ğ‘œğ‘“ ğ‘“ ğ‘ ğ‘’ğ‘¡]]}
    end function
*/
}